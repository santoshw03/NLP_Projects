{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f69c3357-5fb4-44fa-8aa2-019d2af56550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import spacy\n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9c3c637-67fd-4add-b423-ce2f5d65cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83452342-439c-49b2-a389-bdb92ab7694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text  = '''spaCy is an advanced open-source library for Natural Language Processing (NLP) in Python, designed to help developers build applications that process and understand large volumes of text. NLP involves the interaction between computers and human languages, enabling machines to read, interpret, and generate human language in a valuable way. spaCy stands out due to its speed, efficiency, and ease of use, providing pre-trained models, word vectors, and an extensive suite of tools for various NLP tasks such as tokenization, part-of-speech tagging, named entity recognition, dependency parsing, and lemmatization.\n",
    "\n",
    "One of spaCy's strengths is its industrial-grade architecture that emphasizes performance and accuracy. This makes it suitable for production use in large-scale applications. spaCy is also designed to be extensible, allowing users to create custom components and pipelines tailored to specific needs. Its compatibility with other NLP libraries, such as scikit-learn, TensorFlow, and PyTorch, enables seamless integration with machine learning workflows.\n",
    "\n",
    "The library includes various pre-trained models that cater to different languages and NLP tasks. One of the most commonly used models is \"en_core_web_sm,\" a small English model that provides essential functionalities for many NLP applications. This model includes components for tokenization, part-of-speech tagging, dependency parsing, named entity recognition, and lemmatization, all trained on web text to ensure broad coverage and robustness. Despite its relatively small size, \"en_core_web_sm\" offers a good balance between performance and resource efficiency, making it ideal for developers who need a lightweight solution for common NLP tasks.\n",
    "\n",
    "Using \"en_core_web_sm\" with spaCy is straightforward, involving just a few lines of code to load the model and process text. This ease of use allows developers to quickly prototype and deploy NLP applications. Additionally, spaCy's user-friendly documentation and active community support make it accessible to both beginners and experienced practitioners. The library's design also supports fine-tuning and transfer learning, enabling users to adapt pre-trained models to specific domains or tasks.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ad7280-d24e-4875-a503-d6acd5e553fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a064a8e3-dd6e-449d-94e9-40fbc742079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting sentences from text:\n",
    "sentences = [sent.text for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5338cb2-febd-4c34-8a4a-b57d100c7ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting few random sentences:\n",
    "num_of_questions = 5\n",
    "selected_sentences = random.sample(sentences,min(num_of_questions,len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66eba666-da7d-4c69-9725-1c51f74be3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The library's design also supports fine-tuning and transfer learning, enabling users to adapt pre-trained models to specific domains or tasks.\\n\\n\",\n",
       " 'This makes it suitable for production use in large-scale applications.',\n",
       " 'NLP involves the interaction between computers and human languages, enabling machines to read, interpret, and generate human language in a valuable way.',\n",
       " 'This ease of use allows developers to quickly prototype and deploy NLP applications.',\n",
       " \"One of spaCy's strengths is its industrial-grade architecture that emphasizes performance and accuracy.\"]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8993a394-078f-4d96-88f1-bd5aa195e3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcqs = []\n",
    "\n",
    "for sentence in selected_sentences:\n",
    "    sentence = sentence.lower()\n",
    "    sent_doc = nlp(sentence) #creating doc of each sentence from selected sentence\n",
    "    nouns = [token.text for token in sent_doc if token.pos_ == \"NOUN\"] #seperating nouns from each sentence\n",
    "    if len(nouns)<2:\n",
    "        continue        #excluding nouns having less than 2 letters\n",
    "    # print(nouns)\n",
    "\n",
    "    noun_counts = Counter(nouns) #getting count of occurance\n",
    "    # print(noun_counts)\n",
    "\n",
    "    if noun_counts:\n",
    "        subject = noun_counts.most_common(1)[0][0]\n",
    "        # print(subject)\n",
    "        answer_choices = [subject]\n",
    "        question_stem = sentence.replace(subject,\"________\")\n",
    "        # print(question_stem)\n",
    "\n",
    "        for _ in range(3):\n",
    "            distractor = random.choice(list(set(nouns)-set([subject])))\n",
    "            answer_choices.append(distractor)\n",
    "\n",
    "        random.shuffle(answer_choices)\n",
    "        # print(answer_choices)\n",
    "\n",
    "        correct_answer = chr(64 + answer_choices.index(subject)+1) #convert index to letter\n",
    "        mcqs.append((question_stem,answer_choices,correct_answer))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9aebeca6-fb56-495e-b732-f1bc8fecbd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"the ________'s design also supports fine-tuning and transfer learning, enabling users to adapt pre-trained models to specific domains or tasks.\\n\\n\",\n",
       "  ['domains', 'library', 'users', 'domains'],\n",
       "  'B'),\n",
       " ('this makes it suitable for ________ use in large-scale applications.',\n",
       "  ['use', 'applications', 'use', 'production'],\n",
       "  'D'),\n",
       " ('nlp involves the ________ between computers and human languages, enabling machines to read, interpret, and generate human language in a valuable way.',\n",
       "  ['machines', 'interaction', 'machines', 'way'],\n",
       "  'B'),\n",
       " ('this ________ of use allows developers to quickly prototype and deploy nlp applications.',\n",
       "  ['applications', 'ease', 'developers', 'developers'],\n",
       "  'B'),\n",
       " (\"one of ________'s strengths is its industrial-grade architecture that emphasizes performance and accuracy.\",\n",
       "  ['architecture', 'spacy', 'accuracy', 'accuracy'],\n",
       "  'B')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a057a3a5-5ca2-46ee-a177-b7d4643944fd",
   "metadata": {},
   "source": [
    "# A function to do the above task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df57e32a-a444-4aaf-b18e-935290597bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mcqs(text,num_of_questions=5):\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    selected_sentences = random.sample(sentences,min(num_of_questions,len(sentences)))\n",
    "    mcqs = []\n",
    "    for sentence in selected_sentences:\n",
    "        sentence = sentence.lower()\n",
    "        sent_doc = nlp(sentence)\n",
    "        nouns = [token.text for token in sent_doc if token.pos_ == \"NOUN\"]\n",
    "        if len(nouns)<2:\n",
    "            continue \n",
    "        noun_counts = Counter(nouns)\n",
    "        if noun_counts:\n",
    "            subject = noun_counts.most_common(1)[0][0]\n",
    "            answer_choices = [subject]\n",
    "            question_stem = sentence.replace(subject,\"________\")\n",
    "            for _ in range(3):\n",
    "                distractor = random.choice(list(set(nouns)-set([subject])))\n",
    "                answer_choices.append(distractor)\n",
    "            random.shuffle(answer_choices)\n",
    "            correct_answer = chr(64 + answer_choices.index(subject)+1) #convert index to letter\n",
    "            mcqs.append((question_stem,answer_choices,correct_answer))\n",
    "    return mcqs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88d8e21a-d05f-4787-88db-c0522ffe2dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"one of ________'s strengths is its industrial-grade architecture that emphasizes performance and accuracy.\",\n",
       "  ['performance', 'architecture', 'grade', 'spacy'],\n",
       "  'D'),\n",
       " ('the ________ includes various pre-trained models that cater to different languages and nlp tasks.',\n",
       "  ['library', 'tasks', 'models', 'languages'],\n",
       "  'A'),\n",
       " ('________ is an advanced open-source library for natural language processing (nlp) in python, designed to help developers build applications that process and understand large volumes of text.',\n",
       "  ['developers', 'spacy', 'applications', 'developers'],\n",
       "  'B')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing:\n",
    "generate_mcqs(text,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e535d5-0959-4482-b667-cb346f7f46d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
